{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "id": "IHqPtJyh74v7"
      },
      "source": [
        "\n",
        "This material, no matter whether in printed or electronic form,\n",
        "may be used for personal and non-commercial educational use only.\n",
        "Any reproduction of this manuscript,\n",
        "no matter whether as a whole or in parts,\n",
        "no matter whether in printed or in electronic form,\n",
        "requires explicit prior acceptance of the authors.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWyJItim74v-"
      },
      "source": [
        "<!-- Assignment 6 - SS 2023 -->\n",
        "\n",
        "# Adversarial Training (15 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roKHQ2vy74wA"
      },
      "source": [
        "This notebook contains one of the assignments for the exercises in Deep Learning and Neural Nets 2.\n",
        "It provides a skeleton, i.e. code with gaps, that will be filled out by you in different exercises.\n",
        "All exercise descriptions are visually annotated by a vertical bar on the left and some extra indentation,\n",
        "unless you already messed with your jupyter notebook configuration.\n",
        "Any questions that are not part of the exercise statement do not need to be answered,\n",
        "but should rather be interpreted as triggers to guide your thought process.\n",
        "\n",
        "**Note**: The cells in the introductory part (before the first subtitle)\n",
        "perform all necessary imports and provide utility functions that should work without (too much) problems.\n",
        "Please, do not alter this code or add extra import statements in your submission, unless explicitly allowed!\n",
        "\n",
        "<span style=\"color:#d95c4c\">**IMPORTANT:**</span> Please, change the name of your submission file so that it contains your student ID!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAJAuDY874wA"
      },
      "source": [
        "In this assignment, we will play around with adversarial techniques in deep learning.\n",
        "The main goal is to build some understanding of *Generative Adversarial Networks* (GANs).\n",
        "However, we will also take a look at *adversarial training*,\n",
        "which is a collection of methods for fooling neural networks.\n",
        "Although both approaches are completely unrelated,\n",
        "it turns out that is possible to build GANs, starting from adversarial examples.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Um9YLRpc74wB",
        "outputId": "43bb1649-f0bb-42c6-ddbc-d3eeb552b63d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets\n",
        "from PIL import Image\n",
        "\n",
        "torch.manual_seed(1806)\n",
        "torch.cuda.manual_seed(1806)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8-gEUWz74wD",
        "outputId": "cb36c92b-3ecc-4272-b425-bd3065d5fa6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "gdrive/MyDrive/.pytorch\n"
          ]
        }
      ],
      "source": [
        "# google colab data management\n",
        "import os.path\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive')\n",
        "    _home = 'gdrive/MyDrive/'\n",
        "except ImportError:\n",
        "    _home = '~'\n",
        "finally:\n",
        "    data_root = os.path.join(_home, '.pytorch')\n",
        "\n",
        "print(data_root)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Ug8HXxt74wE"
      },
      "outputs": [],
      "source": [
        "class BaseTrainer:\n",
        "\n",
        "    def __init__(self,\n",
        "         model: nn.Module,\n",
        "         criterion: nn.Module,\n",
        "         optimiser: optim.Optimizer,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        model : torch.nn.Module\n",
        "            Neural Network that will be trained.\n",
        "        criterion : torch.nn.Module\n",
        "            Loss function to use for training.\n",
        "        optimiser : torch.optim.Optimizer\n",
        "            Optimisation strategy for training.\n",
        "        tracker : Tracker, optional\n",
        "            Tracker to keep track of training progress.\n",
        "        \"\"\"\n",
        "        self.model = model\n",
        "        self.criterion = criterion\n",
        "        self.optimiser = optimiser\n",
        "\n",
        "    def state_dict(self):\n",
        "        \"\"\" Current state of learning. \"\"\"\n",
        "        return {\n",
        "            \"model\": self.model.state_dict(),\n",
        "            \"objective\": self.criterion.state_dict(),\n",
        "            \"optimiser\": self.optimiser.state_dict(),\n",
        "        }\n",
        "\n",
        "    def load_state_dict(self, state_dict: dict):\n",
        "        \"\"\" Restore learning state. \"\"\"\n",
        "        self.model.load_state_dict(state_dict[\"model\"])\n",
        "        self.criterion.load_state_dict(state_dict[\"objective\"])\n",
        "        self.optimiser.load_state_dict(state_dict[\"optimiser\"])\n",
        "\n",
        "    @property\n",
        "    def device(self):\n",
        "        \"\"\" Device of the (first) model parameters. \"\"\"\n",
        "        return next(self.model.parameters()).device\n",
        "\n",
        "    def _forward(self, data: DataLoader, metric: callable):\n",
        "        device = self.device\n",
        "        for x, y in data:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            outputs = self.model(x)\n",
        "            res = metric(outputs, y)\n",
        "            yield res\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def evaluate(self, data: DataLoader, metric: callable) -> list:\n",
        "        self.model.eval()\n",
        "\n",
        "        results = self._forward(data, metric)\n",
        "        return [res.item() for res in results]\n",
        "\n",
        "\n",
        "    @torch.enable_grad()\n",
        "    def update(self, data: DataLoader) -> list:\n",
        "        opt = self.optimiser\n",
        "        self.model.train()\n",
        "\n",
        "        errs = []\n",
        "        for err in self._forward(data, self.criterion):\n",
        "            errs.append(err.item())\n",
        "\n",
        "            opt.zero_grad()\n",
        "            err.backward()\n",
        "            opt.step()\n",
        "\n",
        "        return errs\n",
        "\n",
        "    @property\n",
        "    def fake_data(self):\n",
        "        return None\n",
        "\n",
        "\n",
        "    def _display_results(self, count: int = 10):\n",
        "        \"\"\"\n",
        "        Display generated images.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        count : int, optional\n",
        "            Number of images to display.\n",
        "        \"\"\"\n",
        "        fake_data = self.fake_data\n",
        "        if fake_data is None:\n",
        "            return\n",
        "\n",
        "        x = fake_data[:count].to(self.device)\n",
        "        ps = self.model.probabilities(x).view(-1).tolist()\n",
        "        print(\"D probs:\", ', '.join([f\"{p:.2f}\" for p in ps]))\n",
        "\n",
        "        im = data_to_image(*x.cpu(), means=(.1307, ), stds=(.3081, ))\n",
        "        display(im, metadata={'width': '100%'})\n",
        "\n",
        "\n",
        "    def train(self, loader: DataLoader, num_epochs: int = 10, vis_every: int = 5):\n",
        "        \"\"\"\n",
        "        Train an auto-encoder for a number of epochs.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        loader : DataLoader\n",
        "            A data loader for iterating over batches of the data.\n",
        "        num_epochs : int, optional\n",
        "            Number of times to iterate the dataset.\n",
        "        vis_every : int, optional\n",
        "            Frequency, during training, of\n",
        "            intermediate visualisation of faked samples.\n",
        "        \"\"\"\n",
        "        # evaluate random performance\n",
        "        errs = self.evaluate(loader, self.criterion)\n",
        "        print(f\"Epoch {0: 2d} - avg loss: {sum(errs) / len(errs):.6f}\")\n",
        "        self._display_results()\n",
        "\n",
        "        # train for some epochs\n",
        "        for epoch in range(1, num_epochs + 1):\n",
        "            errs = self.update(loader)\n",
        "            print(f\"Epoch {epoch: 2d} - avg loss: {sum(errs) / len(errs):.6f}\")\n",
        "\n",
        "            if epoch % vis_every == 0:\n",
        "                self._display_results()\n",
        "\n",
        "        return errs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5zOz1_974wF"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def accuracy(logits, targets):\n",
        "    \"\"\"\n",
        "    Compute the accuracy for given logits and targets.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    logits : (N, K) torch.Tensor\n",
        "        A mini-batch of logit vectors from the network.\n",
        "    targets : (N, ) torch.Tensor\n",
        "        A mini_batch of target scalars representing the labels.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    acc : () torch.Tensor\n",
        "        The accuracy over the mini-batch of samples.\n",
        "    \"\"\"\n",
        "    correct = torch.argmax(logits, dim=-1) == targets\n",
        "    acc = torch.mean(correct.float())\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ix8dzFRs74wF"
      },
      "outputs": [],
      "source": [
        "def data_to_image(*data: torch.Tensor,\n",
        "                  means: tuple = (0, ), stds: tuple = (1., )) -> Image:\n",
        "    \"\"\"\n",
        "    Convert multiple tensors to one big image.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    data0, data1, ... dataN : torch.Tensor\n",
        "        One or more tensors to be merged into a single image.\n",
        "    means : tuple or torch.Tensor, optional\n",
        "        Original mean of the image before normalisation.\n",
        "    stds : tuple or torch.Tensor, optional\n",
        "        Original standard deviation of the image before normalisation.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    image : Image\n",
        "        PIL image with all of the tensors next to each other.\n",
        "    \"\"\"\n",
        "    # concatenate all data\n",
        "    big_pic = torch.cat([x for x in data], dim=-1)\n",
        "\n",
        "    means = torch.tensor(means)\n",
        "    stds = torch.tensor(stds)\n",
        "    to_image = transforms.Compose([\n",
        "        # inverts normalisation of image\n",
        "        transforms.Normalize(-means / stds, 1. / stds),\n",
        "        transforms.Lambda(lambda x: torch.clamp(x, 0, 1)),\n",
        "        transforms.ToPILImage()\n",
        "    ])\n",
        "\n",
        "    return to_image(big_pic)\n",
        "\n",
        "def display_fakes(discriminator: nn.Module, fake_data: torch.Tensor,\n",
        "                  count: int = 10):\n",
        "    \"\"\"\n",
        "    Display the images that are fed as fakes to a discriminator.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    discriminator : nn.Module\n",
        "        The discriminator that is to be fooled by the fakes.\n",
        "    fake_data : (N, C, H, W) torch.Tensor\n",
        "        The fake images to display.\n",
        "    count : int, optional\n",
        "        Number of samples to display from `fake_data`.\n",
        "    \"\"\"\n",
        "    device = next(discriminator.parameters()).device\n",
        "    x = fake_data[:count].to(device)\n",
        "    ps = discriminator.probabilities(x).view(-1).tolist()\n",
        "    print(\"D probs:\", ', '.join([f\"{p:.2f}\" for p in ps]))\n",
        "\n",
        "    im = data_to_image(*x.cpu(), means=(.1307, ), stds=(.3081, ))\n",
        "    display(im, metadata={'width': '100%'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Bs9Zbfm74wF"
      },
      "outputs": [],
      "source": [
        "def evaluate_attack(attack: callable, network: nn.Module, data: DataLoader,\n",
        "                    loss_func: nn.Module, vis_count: int = 8, **kwargs):\n",
        "    \"\"\"\n",
        "    Evaluate an adversarial attack on some data.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    attack : callable\n",
        "        Function that computes the adversarial example.\n",
        "        Will be called as `attack(x, y, network, loss_func, **kwargs).\n",
        "    network : nn.Module\n",
        "        The network to attack.\n",
        "    data : DataLoader\n",
        "        Data for the attack.\n",
        "    loss_func : nn.Module\n",
        "        Objective for the attack.\n",
        "    vis_count : int, optional\n",
        "        Number of adversarial examples to visualise.\n",
        "    kwargs\n",
        "        Keyword arguments for the attack function.\n",
        "    \"\"\"\n",
        "    dev = next(network.parameters()).device\n",
        "    network.eval()\n",
        "\n",
        "    accuracies = []\n",
        "    for x, y in data:\n",
        "        x, y = x.to(dev), y.to(dev)\n",
        "        adv_x = attack(x, y, network, loss_func, **kwargs)\n",
        "        adv_x = adv_x.clamp(x.min(), x.max())  # put in valid range\n",
        "\n",
        "        # compute accuracy on adversarial examples\n",
        "        with torch.no_grad():\n",
        "            logits = network(adv_x)\n",
        "            acc = accuracy(logits, y)\n",
        "            accuracies.append(acc.item())\n",
        "\n",
        "    print(f\"Adversarial accuracy: {100 * accuracies[0]:.2f}%\")\n",
        "\n",
        "    # collect relevant data\n",
        "    x_ref, y_ref = x[:vis_count], y[:vis_count]\n",
        "    x_adv, y_adv = adv_x[:vis_count], logits[:vis_count].argmax(-1)\n",
        "    with torch.no_grad():\n",
        "        y_pred = network(x_ref).argmax(-1)\n",
        "\n",
        "    # visualise adversaries\n",
        "    ref_im = data_to_image(*x_ref.cpu(), means=(.1307, ), stds=(.3081, ))\n",
        "    display(ref_im, metadata={'width': '100%'})\n",
        "    print(\"ground truth: \", y_ref.tolist())\n",
        "    print(\"before attack:\", y_pred.tolist())\n",
        "    print(\"after attack: \", y_adv.tolist())\n",
        "    adv_im = data_to_image(*x_adv.cpu(), means=(.1307, ), stds=(.3081, ))\n",
        "    display(adv_im, metadata={'width': '100%'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EekzpD2q74wG"
      },
      "outputs": [],
      "source": [
        "class DiscriminatorTrainer(BaseTrainer):\n",
        "\n",
        "    def __init__(self, model, criterion, optimiser,\n",
        "                 dataset: \"RealOrFakeDataset\", epsilon: float = 0.1):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        dataset : RealOrFakeDataset\n",
        "            The dataset that will be used to train the discriminator.\n",
        "        epsilon: float, optional\n",
        "            The maximum allowed perturbation for the adversarial attacks.\n",
        "        \"\"\"\n",
        "        super().__init__(model, criterion, optimiser)\n",
        "        self.dataset = dataset\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    @property\n",
        "    def fake_data(self):\n",
        "        return self.dataset.fake_data\n",
        "\n",
        "    def update(self, data: DataLoader) -> list:\n",
        "        results = super().update(data)\n",
        "        self.dataset.update_fake_examples(self.model, self.criterion, self.epsilon)\n",
        "        return results\n",
        "\n",
        "\n",
        "def train_gan(gan: nn.Module, loader: DataLoader, objective: nn.Module,\n",
        "              optimiser: optim.Optimizer, num_epochs: int = 10, vis_every: int = 5):\n",
        "    \"\"\"\n",
        "    Train a GAN for a number of epochs.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    gan : nn.Module\n",
        "        The GAN to train\n",
        "    loader : DataLoader\n",
        "        A data loader for iterating over batches of the data.\n",
        "        This can be a standard, \"supervised\" dataloader.\n",
        "    objective : nn.Module\n",
        "        The loss function to optimise during training.\n",
        "    optimiser : optim.Optimizer\n",
        "        The optimiser to use for training.\n",
        "    num_epochs : int, optional\n",
        "        Number of times to iterate the dataset.\n",
        "    vis_every : int, optional\n",
        "        Frequency, during training, of\n",
        "        intermediate visualisation of fake samples.\n",
        "\n",
        "    \"\"\"\n",
        "    g_errs, d_errs = [], []\n",
        "    for x, _ in loader:\n",
        "        x = x.to(device)\n",
        "        g_errs.append(generator_error(gan, x, objective).item())\n",
        "        d_errs.append(discriminator_error(gan, x, objective).item())\n",
        "    loss_report = ', '.join([\n",
        "        f\"avg G loss: {sum(g_errs) / len(g_errs):.5f}\",\n",
        "        f\"avg D loss: {sum(d_errs) / len(d_errs):.5f}\"\n",
        "    ])\n",
        "    print(f'Epoch {0: 2d}', loss_report, sep=' - ')\n",
        "    fake_data = gan.generator.generate(batch_size=10)\n",
        "    display_fakes(gan.discriminator, fake_data)\n",
        "\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        g_errs, d_errs = update_gan(gan, loader, objective, optimiser)\n",
        "        loss_report = ', '.join([\n",
        "            f\"avg G loss: {sum(g_errs) / len(g_errs):.5f}\",\n",
        "            f\"avg D loss: {sum(d_errs) / len(d_errs):.5f}\"\n",
        "        ])\n",
        "        print(f'Epoch {epoch: 2d}', loss_report, sep=' - ')\n",
        "        if epoch % vis_every == 0:\n",
        "            fake_data = gan.generator.generate(batch_size=10)\n",
        "            display_fakes(gan.discriminator, fake_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2AciTrS74wH"
      },
      "source": [
        "## Adversarial Examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "id": "CMuGWGne74wH",
        "outputId": "aabf6a6e-4f2b-46fb-f24a-392b197ee730"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Dataset not found. You can use download=True to download it",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-45a875f0e524>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.1307\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m.3081\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m ])\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmnist_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_processing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dataset not found. You can use download=True to download it\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Dataset not found. You can use download=True to download it"
          ]
        }
      ],
      "source": [
        "# set up training (nothing to do here)\n",
        "\n",
        "pre_processing = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((.1307, ), (.3081, ))\n",
        "])\n",
        "mnist_train = datasets.MNIST(data_root, transform=pre_processing)\n",
        "train_loader = DataLoader(mnist_train, shuffle=True, batch_size=128, num_workers=4)\n",
        "\n",
        "mnist_net = nn.Sequential(\n",
        "    nn.Conv2d(1, 8, 4, stride=2),\n",
        "    nn.ELU(),\n",
        "    nn.Conv2d(8, 32, 3, stride=2),\n",
        "    nn.ELU(),\n",
        "    nn.Conv2d(32, 64, 6),\n",
        "    nn.ELU(),\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(64, 10)\n",
        ").to(device)\n",
        "\n",
        "trainer = BaseTrainer(\n",
        "    model=mnist_net,\n",
        "    criterion=nn.CrossEntropyLoss(),\n",
        "    optimiser=optim.SGD(mnist_net.parameters(), lr=1e-2, momentum=.9)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8c_IeuXY74wI",
        "outputId": "8d81e796-bc98-49fe-ea72-4addd0968e04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  0 - avg loss: 2.310794\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  1 - avg loss: 0.356059\n",
            "Epoch  2 - avg loss: 0.112316\n",
            "Epoch  3 - avg loss: 0.074124\n",
            "Epoch  4 - avg loss: 0.056325\n",
            "Epoch  5 - avg loss: 0.046636\n",
            "Epoch  6 - avg loss: 0.036963\n",
            "Epoch  7 - avg loss: 0.030945\n",
            "Epoch  8 - avg loss: 0.025034\n",
            "Epoch  9 - avg loss: 0.020623\n",
            "Epoch  10 - avg loss: 0.018712\n",
            "Epoch  11 - avg loss: 0.015201\n",
            "Epoch  12 - avg loss: 0.013424\n",
            "Epoch  13 - avg loss: 0.010467\n",
            "Epoch  14 - avg loss: 0.008822\n",
            "Epoch  15 - avg loss: 0.007537\n",
            "Epoch  16 - avg loss: 0.007254\n",
            "Epoch  17 - avg loss: 0.005839\n",
            "Epoch  18 - avg loss: 0.004752\n",
            "Epoch  19 - avg loss: 0.003479\n",
            "Epoch  20 - avg loss: 0.002577\n",
            "Train accuracy: 99.76%\n",
            "\n",
            "CPU times: user 40.9 s, sys: 7.46 s, total: 48.3 s\n",
            "Wall time: 4min 57s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# train MNIST classifier\n",
        "errs = trainer.train(train_loader, num_epochs=20)\n",
        "errs = trainer.evaluate(train_loader, accuracy)\n",
        "print(f\"Train accuracy: {100 * sum(errs) / len(errs):.2f}%\")\n",
        "torch.save(trainer.state_dict(), \"mnist_net.pt\")  # for testing\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MaUrR0-74wI",
        "outputId": "1d40b79b-0b81-4274-fa68-c07181b9ad86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval loss: 0.06838\n",
            "Eval accuracy: 98.39%\n"
          ]
        }
      ],
      "source": [
        "# test MNIST classifier\n",
        "trainer.load_state_dict(torch.load(\"mnist_net.pt\"))  # for testing\n",
        "mnist_test = datasets.MNIST(data_root, train=False, transform=pre_processing)\n",
        "test_loader = DataLoader(mnist_test, batch_size=len(mnist_test), num_workers=4)\n",
        "errs = trainer.evaluate(test_loader, trainer.criterion)\n",
        "print(f\"Eval loss: {errs[0]:.5f}\")\n",
        "errs = trainer.evaluate(test_loader, accuracy)\n",
        "print(f\"Eval accuracy: {100 * errs[0]:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HIrA8I774wI"
      },
      "source": [
        "It has become extremely easy to get good models for plenty of tasks.\n",
        "It only takes a few lines of code and a handful of minutes\n",
        "to get a model that is able to recognise handwritten digits.\n",
        "This does not mean, however, that the network *understands* these images.\n",
        "It turns out that even the best models can easily be fooled\n",
        "by creating what is known as *adversarial examples*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbHENW9O74wJ"
      },
      "source": [
        "There are mainly two ways to make a strong network look stupid:\n",
        " 1. Change existing images until the network mis-classifies them,\n",
        " 2. Make predictions on random noise (out-of-distribution images).\n",
        "\n",
        "The first approach is an active topic in Machine Learning research.\n",
        "The main goal is to find the smallest possible perturbations\n",
        "that are required to make the network misclassify its inputs.\n",
        "\n",
        "The second approach can be considered silly because in most cases,\n",
        "a network is simply not able to express that it has no idea what to predict.\n",
        "Nevertheless, this can make systems that rely on neural networks vulnerable.\n",
        "E.g. face recognition software being fooled by carefully constructed noise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zam2077y74wJ"
      },
      "source": [
        "### Exercise 1: Projected Gradient Ascent (5 points)\n",
        "\n",
        "One of the easiest ways to construct an adversarial example\n",
        "is to maximise the loss by using gradient ascent on the inputs.\n",
        "After all, the parameters of a neural network are also the result\n",
        "of a gradient descent that minises the loss function.\n",
        "\n",
        "In order to keep the perturbations to the original image small,\n",
        "a constraint is added to the gradient ascent for adversarial examples:\n",
        "the adversarial example must lie in an epsilon-ball around the original input.\n",
        "This procedure is also known as *projected gradient ascent*.\n",
        "\n",
        " > Implement the `adversarial_attack` function below\n",
        " > so that it implements projected gradient ascent as described above.\n",
        " > To speed up the process of finding adversarial examples,\n",
        " > you can use the sign of the gradients instead of the pure gradients.\n",
        " > Make sure not to return the computational graph!\n",
        "\n",
        "**Hint:** If you are having problems with gradient errors, your computations might involve an unwanted gradient flow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_NIOQRGPaqsV"
      },
      "outputs": [],
      "source": [
        "def adversarial_attack(x: torch.Tensor, y: torch.Tensor,\n",
        "                       network: nn.Module, loss_func: nn.Module,\n",
        "                       epsilon: float = .1, eta: float = .1, steps: int = 10):\n",
        "    \"\"\"\n",
        "    Compute an adversarial example for a network from a given input.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    x : torch.Tensor\n",
        "        The reference input for the network.\n",
        "    y : torch.Tensor\n",
        "        The label for the reference input.\n",
        "    network : nn.Module\n",
        "        The network to compute the adversary for.\n",
        "    loss_func : nn.Module\n",
        "        The loss function the network was trained with.\n",
        "    epsilon : float, optional\n",
        "        The radius of the ball to keep the adversary within.\n",
        "    eta : float, optional\n",
        "        The step size to use for computing the adversary.\n",
        "    steps : int, optional\n",
        "        The number of gradient steps to take.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    adversary : torch.Tensor\n",
        "        The adversarial example (`x + perturbation`).\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE\n",
        "    # raise NotImplementedError()\n",
        "    x_advers = x.clone().detach().requires_grad_(True)\n",
        "\n",
        "    for step in range(steps):\n",
        "        _x_advers = x_advers.clone().detach().requires_grad_(True)\n",
        "        prediction = network(_x_advers)\n",
        "        loss = loss_func(prediction, y)\n",
        "        loss.backward()\n",
        "\n",
        "        # Compute gradients\n",
        "        gradients = torch.sign(_x_advers.grad) * eta\n",
        "\n",
        "       # Update adversarial example without tracking gradients\n",
        "        x_advers = x_advers + gradients.detach()\n",
        "\n",
        "        # Clamp the perturbed images to ensure they remain within the epsilon ball\n",
        "        x_advers = torch.max(torch.min(x_advers, x + epsilon), x - epsilon)\n",
        "\n",
        "        # Further clamping to ensure values remain in valid range\n",
        "        x_advers = x_advers.clamp(x - epsilon, x + epsilon).detach()\n",
        "\n",
        "    return x_advers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVr9nckS74wK"
      },
      "outputs": [],
      "source": [
        "# Test Cell: do not edit or delete!\n",
        "x = torch.ones(1, 1, 28, 28).to(trainer.device)\n",
        "y = torch.zeros(1, dtype=torch.long).to(trainer.device)\n",
        "x_adv = adversarial_attack(x, y, trainer.model, trainer.criterion, epsilon=0.1)\n",
        "assert x.shape == x_adv.shape, (\n",
        "    \"ex1: adversarial_attack produces outputs with incorrect shape (-1 point)\"\n",
        ")\n",
        "assert torch.abs(x - x_adv).max() <= 0.1 + 1e-5, (\n",
        "    \"ex1: adversarial_attack produces outputs outside of epsilon ball (-1 point)\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qd0wP8kR74wK"
      },
      "outputs": [],
      "source": [
        "# Test Cell: do not edit or delete!\n",
        "assert trainer.model(x_adv)[:, y] < trainer.model(x)[:, y], (\n",
        "    \"ex1: adversarial_attack produces outputs with better results (-1 point)\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQkMb3Uq74wK"
      },
      "outputs": [],
      "source": [
        "# Test Cell: do not edit or delete!\n",
        "assert len(torch.abs(x - x_adv).unique()) <= 5, (\n",
        "    \"ex1: adversarial_attack does not seem to change pixels fast enough (-1 point)\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AuBDBTC674wL"
      },
      "outputs": [],
      "source": [
        "# Test Cell: do not edit or delete!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96ltW3wi74wL"
      },
      "outputs": [],
      "source": [
        "# Test Cell: do not edit or delete!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNeYzDNC74wL"
      },
      "outputs": [],
      "source": [
        "# Test Cell: do not edit or delete!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "VzrWHGhK74wM",
        "outputId": "480caf35-bef2-4045-daad-5599eb3edb97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adversarial accuracy: 51.42%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=224x28>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOAAAAAcCAAAAABdFuxfAAAFLklEQVR4nO2YbWiVZRjHL3EoR6bgdg6NRoehbuLQcqgg6gSXLqWmmOdEYJDUlyUsdTHShTIxJ6O5jNUsxU2dLo+lk4qB1XzBrXyZsiOEr5uYtjM3NpzOjux+/tfpw85z9Dz39TxZYfrB/6fr/K775bqe+/0QPdMzPdUa8mjFPnC95KOtv+x5vME8OQUAALjstS+SwQUiH1GF0w7Vng4FAPxWcQhYY1/mDeN1kacrheWiJ+ta1Mh9wabNPF4+VIOeY6Vppj0qL8E+okfX1AEE0xJp2DmU2xfa1CdiT5NtgqtDUePzfXKTyTeYXVY4umsgYNqjrvalW9wjvzgu5uw7XLN11ji5H8pTwRQiWhPGHJsSRJP6qyT8/hGlFAIF2bor4YSZ4LLgCLHNxcx7rXuEuxGVsR+f4F2Le+k1IFlqq52Zua85qv1T473eJCKiIBwS9PFsCUMppaDU1Smaa55RGrVWGR6p7rAzzAusMBeIFc7kA4nx3tQuBuqShMZyVs1fVXuDrzPzwB/M0lQsCqNZmzAxnW6XRqEhAgBd7QCsrkndl8zojskJTmMesDLPV1hm2pkhfsvi3gIG0Fs4TA5ydM7InJycmZ5ufk93vhZGSBwkIiJK44sCnd0GpVRlXnaJUvkW377wtKiVFIGYYCnzD1ZWG2mJfch8rrZ4vX1oPQwglGIbKBHREgSFQS4BttjXeZtP6DAtpKCulrmIvB3q7sq4xe+7c940N6NR3BeaODzZynbju2hZ14YebVYs4uM0/J0rHDklzVJTnluRJTo99CdqEnVsqpzzdJiuFH52ExFRgYIa+7AvYJizJK1zIEdqcgZzjwZ3A0frc3Nzczc2AQGr149FRNQAPuoQKq3n3okaTOnCrbFC4aim95wdrtN0pU5Fz3jvyfgER103TLPUOE+SVjB/rMEpNwEGAAauaAHVYzsRdYE32YdKM++zsKc3A5sdKn0U2SvQ9AdbS9rpCB6+53mM2K+A8bXYZi33pup09Jwy7iwrK5sI7NKcfrSO99epHu7OtI91I/+kr4iFYTQ6jfo3vFig5UqZpnWKulrMde6BfA+YZXC7Q49j+Jy+MyX1goHD4y7iS9uKrrPhGRpMPuk8gCmdFyR8yUzQMzuk0BF3Iw0Yv/r9fv/6PScMQ9iziRYxb3PocifmCXTu7Qh/NpxKud12Pa3lBh2WAtYjNU4fco2EYwluUUq1xU/8CfvvGYZhdIaUYYinay33TpP4oPzclyXxudUViUSuemH+DupVdXu6TsOA48mylSskbCbY0KaU0o60LJ/P5yPaZRhaRSJKNTjo0GM1S4s+pjfxu3xQJLdxnYDDQKbb7XYnUILbnV5VVVUZ/9FvsrjRXwYWLLgJRCDcZEytM4xJAvYzb7BPgEL94gCaGlKHtRIfeob1vZeIwoPPQez7tC5qFT/szlZygiuVMu+iqlIqQERUIueez11u+wTyudPeSUQ0+R4yBJzB0nlNdBAPdD8cDhQVxc3jzXxWf7YRkbcjmmBH41jbW+w6eYrWc4vDU68VOyjR8RldyN/qXXqvcaH8F0ZRcXFxHYDtxcUTNKfrAq+We8muGExQfg8OapPRL9CE89zkUKkV25a22O0jRETkucwvanAj81Sh7N8pofmQ7fjMP6gOvDLf6Vt3dq8Q6NBq3ulQqRWMbXb/AwzKq29D2Xf+XYL/Td+Ly5ee3+E07NlHSp6zeRLF9GO/9TqzmvnK+H8S29Otke0LiYjiVnLw5d4nE8zj0N0xTzqC/0d/ASF/lO0b1n1bAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "width": "100%"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ground truth:  [7, 2, 1, 0, 4, 1, 4, 9]\n",
            "before attack: [7, 2, 1, 0, 4, 1, 4, 9]\n",
            "after attack:  [7, 2, 7, 2, 9, 7, 8, 4]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=224x28>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "width": "100%"
          }
        }
      ],
      "source": [
        "# sanity check\n",
        "trainer.model.requires_grad_(False)  # disable parameter gradients\n",
        "evaluate_attack(adversarial_attack, trainer.model, test_loader, trainer.criterion, epsilon=.3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFk7ANUg74wM"
      },
      "source": [
        "## Fooling a Dummy Network\n",
        "\n",
        "Adversarial examples are considered an analysis tool\n",
        "that can help to gain insights in how neural networks behave.\n",
        "However, when pushing these methods, it turns out that\n",
        "adversarial examples can actually also be used to generate new images.\n",
        "The key point to getting useful images, is to attack the right model.\n",
        "\n",
        "Consider the task of predicting whether an input is *real* or *fake*.\n",
        "A *real* sample would be defined as an input that comes from the dataset,\n",
        "whereas a *fake* example is an input that does not appear in the dataset.\n",
        "It should be relatively easy to build a binary classification model for this task.\n",
        "Let us denote this model as a *discriminator*,\n",
        "since it discriminates between *real* and *fake* images.\n",
        "\n",
        "By using an adversarial attack on this model\n",
        "*fake* inputs can be altered to look more like *real* samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gg4J6IVl74wM"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    \"\"\" Network for deciding whether a MNIST image is real or fake. \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(1, 8, 4, stride=2),\n",
        "            nn.ELU(),\n",
        "            nn.Conv2d(8, 32, 3, stride=2),\n",
        "            nn.ELU(),\n",
        "            # (old-school) global average pooling\n",
        "            nn.Conv2d(32, 64, 6),\n",
        "            nn.ELU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def probabilities(self, x):\n",
        "        \"\"\"\n",
        "        Compute probability of inputs being real.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : torch.Tensor\n",
        "            The inputs to compute the probabilities for.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        p : torch.Tensor\n",
        "            Values between 0 (fake) and 1 (real).\n",
        "\n",
        "        Notes\n",
        "        -----\n",
        "        Gradient computations are disabled.\n",
        "        \"\"\"\n",
        "        logits = self.model(x)\n",
        "        return torch.sigmoid(logits)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def predict(self, x):\n",
        "        \"\"\"\n",
        "        Make a hard prediction on fake or real.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : torch.Tensor\n",
        "            The inputs to compute the prediction for.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        y : torch.Tensor\n",
        "            Either 0 (fake) or 1 (real).\n",
        "\n",
        "        Notes\n",
        "        -----\n",
        "        Gradient computations are disabled.\n",
        "        \"\"\"\n",
        "        logits = self.model(x)\n",
        "        return (logits > 0).int()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdLTFlTx74wN"
      },
      "source": [
        "###### Paradox of the Discriminator\n",
        "\n",
        "If we compute adversarial examples for the discriminator,\n",
        "we can only get more *fake* inputs,\n",
        "since the adversaries are not part of the dataset.\n",
        "Now, a successful adversary of a *real* input,\n",
        "should be classified as a *fake*, and vice versa.\n",
        "Note that successful adversaries of *real* inputs\n",
        "will be **correctly** classified as *fake*.\n",
        "Hence, the obtained example would not really be adversarial.\n",
        "Therefore, the only truly adversarial examples for this model\n",
        "are *fake* inputs that are converted to be recongised as *real*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XUKwaz074wN"
      },
      "source": [
        "### Exercise 2: Discriminator Data (3 points)\n",
        "\n",
        "Training a model that is able to discriminate between *real* and *fake*,\n",
        "is not entirely straightforward.\n",
        "The main problem is to obtain a reasonable dataset\n",
        "that represents both classes equally well.\n",
        "\n",
        "One solution is to use random noise for the *fake* inputs.\n",
        "However, this often makes things too easy\n",
        "and will not produce a particularly strong model.\n",
        "To counter this issue, we can use an adversarial attack\n",
        "to make the *fake* inputs appear more real\n",
        "after every epoch of discriminator training.\n",
        "This turns out to produce a reasonable discriminator\n",
        "as well as reasonably good *fake* inputs.\n",
        "\n",
        " > Implement the `update_fake_examples` method of the `RealOrFakeDataset`\n",
        " > to implement the approach described above.\n",
        " > Make sure to keep the adversarial examples in a valid range!\n",
        "\n",
        "**Hint:** You can use the `adversarial_attack` function from the previous exercise to compute adversarial examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APk6W3ss74wN"
      },
      "outputs": [],
      "source": [
        "class RealOrFakeDataset(Dataset):\n",
        "    \"\"\" Dataset for enhancing a (small) dataset with fake inputs. \"\"\"\n",
        "\n",
        "    def __init__(self, real_dataset, seed: int = None):\n",
        "        super().__init__()\n",
        "        self.ref_dataset = real_dataset\n",
        "\n",
        "        # control randomness\n",
        "        rng = torch.Generator()\n",
        "        if seed is not None:\n",
        "            rng.manual_seed(seed)\n",
        "\n",
        "        # get real, pre-processed data\n",
        "        real_data = torch.stack([x for x, _ in real_dataset])\n",
        "        mean, std = real_data.mean(), real_data.std()\n",
        "        min_x, max_x = real_data.min(), real_data.max()\n",
        "        self.min_x, self.max_x = min_x, max_x\n",
        "        # generate fake data (with similar statistics)\n",
        "        self.fake_data = torch.empty_like(real_data)\n",
        "        self.fake_data.normal_(mean, std, generator=rng).clamp_(min_x, max_x)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        new_index = index - len(self.ref_dataset)\n",
        "        if new_index < 0:\n",
        "            x, _ = self.ref_dataset[index]\n",
        "            return x, torch.ones(1)\n",
        "\n",
        "        return self.fake_data[new_index], torch.zeros(1)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ref_dataset) + len(self.fake_data)\n",
        "\n",
        "    @property\n",
        "    def raw_folder(self):\n",
        "        return os.path.join(self.root, 'MNIST', 'raw')\n",
        "\n",
        "    @property\n",
        "    def processed_folder(self):\n",
        "        return os.path.join(self.root, 'MNIST', 'processed')\n",
        "\n",
        "    def update_fake_examples(self, network: nn.Module, loss_func: nn.Module,\n",
        "                             epsilon: float = .1):\n",
        "        \"\"\"\n",
        "        Update the fake examples of this dataset.\n",
        "\n",
        "        The fake examples are updated by computing adversarial examples\n",
        "        for the network that is trained with the data from this dataset.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        network : nn.Module\n",
        "            Network to use for computing adversarial examples.\n",
        "        loss_func : nn.Module\n",
        "            Loss function to use for computing adversarial examples.\n",
        "        epsilon : float, optional\n",
        "            Epsilon parameter for the adversarial attack.\n",
        "\n",
        "        Notes\n",
        "        -----\n",
        "        This method overwrites the fake samples.\n",
        "        It should not be necessary to create a new dataset\n",
        "        or set up a new data loader.\n",
        "        \"\"\"\n",
        "        device = next(network.parameters()).device\n",
        "        # YOUR CODE HERE\n",
        "        #raise NotImplementedError()\n",
        "\n",
        "        labels = torch.zeros(self.fake_data.shape[0], 1).to(device)\n",
        "\n",
        "        fake_data_ = adversarial_attack(\n",
        "\n",
        "            self.fake_data.to(device),\n",
        "            labels,\n",
        "            network ,\n",
        "            loss_func,\n",
        "            epsilon=epsilon,\n",
        "            eta = .1,\n",
        "            steps=10\n",
        "\n",
        "            )\n",
        "\n",
        "        self.fake_data = fake_data_.to(self.fake_data.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IB4aJv-J74wO"
      },
      "outputs": [],
      "source": [
        "# Test Cell: do not edit or delete!\n",
        "discriminator = Discriminator()\n",
        "bce = nn.BCEWithLogitsLoss()\n",
        "data = RealOrFakeDataset(torch.utils.data.Subset(mnist_train, range(64)))\n",
        "\n",
        "old_samples = data.fake_data.clone()\n",
        "data.update_fake_examples(discriminator, bce)\n",
        "new_samples = data.fake_data\n",
        "assert torch.any(old_samples != new_samples), (\n",
        "    \"ex2: update_fake_examples does nothing (-1 point)\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yyew_Zzj74wP"
      },
      "outputs": [],
      "source": [
        "# Test Cell: do not edit or delete!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmnvRTRt74wP"
      },
      "outputs": [],
      "source": [
        "# Test Cell: do not edit or delete!\n",
        "assert torch.all(discriminator(new_samples) > discriminator(old_samples)), (\n",
        "    \"ex2: update_fake_examples does not make samples more real (-1 point)\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8rUpn0c74wQ"
      },
      "outputs": [],
      "source": [
        "# Test Cell: do not edit or delete!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIdjmHix74wR"
      },
      "source": [
        "### Exercise 3: Training the Discriminator (1 point)\n",
        "\n",
        "Finally, we can use this dataset for training the discriminator.\n",
        "By updating the *fake* inputs after every epoch of training,\n",
        "the quality of the *fake* inputs, and therefore also the discriminator,\n",
        "should improve steadily during training.\n",
        "\n",
        "Time to test if this actually works.\n",
        "The `train_discriminator` function (in the preamble)\n",
        "implements a training loop that updates the fake examples every epoch.\n",
        "The code below is able to train the discriminator to zero loss.\n",
        "However, the *fake* images do not look very realistic.\n",
        "\n",
        " > Play around with some of the hyperparameters (lr, epsilon, ...)\n",
        " > to get more realistic *fake* images,\n",
        " > so that the task of the discriminator becomes harder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "t4gOGddc74wR",
        "outputId": "7fe232cd-3f2e-4c13-f913-c0c22fb822bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  0 - avg loss: 0.691680\n",
            "D probs: 0.52, 0.52, 0.50, 0.51, 0.51, 0.49, 0.50, 0.51, 0.49, 0.50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=280x28>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "width": "100%"
          }
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 23.36 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 12.38 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  1 - avg loss: 0.002412\n",
            "Epoch  2 - avg loss: 0.036935\n",
            "Epoch  3 - avg loss: 0.032771\n",
            "Epoch  4 - avg loss: 0.013884\n",
            "Epoch  5 - avg loss: 0.022494\n",
            "D probs: 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 0.99, 1.00, 1.00\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=280x28>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "width": "100%"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  6 - avg loss: 0.020717\n",
            "Epoch  7 - avg loss: 0.023806\n",
            "Epoch  8 - avg loss: 0.033874\n",
            "Epoch  9 - avg loss: 0.025040\n",
            "Epoch  10 - avg loss: 0.025984\n",
            "D probs: 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=280x28>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "width": "100%"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  11 - avg loss: 0.024832\n",
            "Epoch  12 - avg loss: 0.028973\n",
            "Epoch  13 - avg loss: 0.024425\n",
            "Epoch  14 - avg loss: 0.028599\n",
            "Epoch  15 - avg loss: 0.019801\n",
            "D probs: 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=280x28>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "width": "100%"
          }
        }
      ],
      "source": [
        "d_data = RealOrFakeDataset(mnist_train)\n",
        "d_loader = DataLoader(d_data, batch_size=128, shuffle=True)\n",
        "\n",
        "discriminator = Discriminator().to(device)\n",
        "trainer = DiscriminatorTrainer(\n",
        "    model=discriminator,\n",
        "    criterion=nn.BCEWithLogitsLoss(),\n",
        "    optimiser=optim.Adam(discriminator.parameters(), lr=0.002),\n",
        "    dataset=d_data,\n",
        "    epsilon=0.4\n",
        ")\n",
        "\n",
        "# YOUR CODE HERE\n",
        "#raise NotImplementedError()\n",
        "\n",
        "_ = trainer.train(d_loader, num_epochs=15, vis_every=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSMGPFiw74wR"
      },
      "source": [
        "## Generative Adversarial Modelling\n",
        "\n",
        "The previously discussed approach, using adversarial training,\n",
        "is able to create somewhat realistic inputs.\n",
        "Although it might be considered a way to generate new images,\n",
        "it is not very practical because it does not allow\n",
        "to generate samples after training.\n",
        "\n",
        "Although Generative Adversarial Nets (GANs)\n",
        "do not really have a connection with adversarial examples\n",
        "(except for the main author and the name),\n",
        "the goal is also to \"fool\" a discriminator network.\n",
        "Instead of using adversarial examples as *false* examples, however,\n",
        "GANs use a decoder-style network, referred to as *generator*\n",
        "that maps from a known distribution to the input space."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2TdwxStE74wS"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    \"\"\" Network for creating fake MNIST images. \"\"\"\n",
        "\n",
        "    def __init__(self, latent_dim: int = 64):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        latent_dim : int, optional\n",
        "            Dimensions of the latent space, from which to sample.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.model = nn.Sequential(\n",
        "            nn.ConvTranspose2d(latent_dim, 32, 6),\n",
        "            nn.ELU(),\n",
        "            nn.ConvTranspose2d(32, 8, 3, stride=2),\n",
        "            nn.ELU(),\n",
        "            nn.ConvTranspose2d(8, 1, 4, stride=2),\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        x = self.model(z.view(-1, self.latent_dim, 1, 1))\n",
        "        return x\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def sample(self, batch_size: int):\n",
        "        \"\"\"\n",
        "        Sample in the latent space of the generator.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        batch_size : int\n",
        "            Number of samples to sample.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        z : (batch_size, latent_dim) torch.Tensor\n",
        "            A random vector in the latent space.\n",
        "\n",
        "        Notes\n",
        "        -----\n",
        "        Gradient computations are disabled.\n",
        "        \"\"\"\n",
        "        z = torch.randn(batch_size, self.latent_dim)\n",
        "        return z.to(self.model[0].weight.device)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def generate(self, z = None, batch_size: int = 1, bounded: bool = True):\n",
        "        \"\"\"\n",
        "        Generate one or more random images.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        z : (N, latent_dim) torch.Tensor\n",
        "            Latent vector(s) to use for generation.\n",
        "        batch_size : int, optional\n",
        "            Number of images to generate.\n",
        "            This parameter is ignored if `z` is specified.\n",
        "        bounded : bool, optional\n",
        "            Flag to assure that pixel values are in a valid range.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        x : (batch_size, C, H, W) torch.Tensor\n",
        "            Generated image(s).\n",
        "        \"\"\"\n",
        "        if z is None:\n",
        "            z = self.sample(batch_size)\n",
        "\n",
        "        raw = self.forward(z)\n",
        "\n",
        "        if bounded:\n",
        "            raw.clamp_(-0.4242, 2.8215)  # MNIST range\n",
        "\n",
        "        return raw"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZD4xpKbV74wS"
      },
      "source": [
        "### Excercise 4: Min-Max Game (6 points)\n",
        "\n",
        "\n",
        "The goal of the generator is to create images that maximise the loss\n",
        "that the discriminator attempts to minimise.\n",
        "The result is a min-max game between generator and discriminator.\n",
        "Mathematically, this leads to the following optimisation target:\n",
        "$$\\begin{aligned}\n",
        "\\max_d \\min_g \\mathbb{E}[\\log d(X)] + \\mathbb{E}[\\log(1 - d(g(Z)))].\n",
        "\\end{aligned}$$\n",
        "Note that this function is simply the negated binary cross-entropy loss.\n",
        "\n",
        " > Finish the implementation of the `update_gan` function,\n",
        " > including the `generator_error` and `discriminator_error` functions.\n",
        " > Make sure that the generator-error is used to update only the generator,\n",
        " > i.e. does not affect the discriminator, and vice versa.\n",
        " > To achieve this, you will need to control the gradients\n",
        " > with the techniques discussed in assignment 1.\n",
        " > Also, you do not want to directly maximise the error term for the generator,\n",
        " > since it suffers from vanishing gradients.\n",
        " > Think about an alternative, but equivalent optimisation problem.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPfb-0jq74wT"
      },
      "outputs": [],
      "source": [
        "def generator_error(gan: nn.Module, real_x: torch.Tensor, loss_func: nn.Module):\n",
        "    \"\"\"\n",
        "    Construct the gradient graph for updating the generator.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    gan : nn.Module\n",
        "        Module with `generator` and `discriminator` sub-modules.\n",
        "    real_x: torch.Tensor\n",
        "        Mini-batch from target distribution.\n",
        "    loss_func: nn.Module\n",
        "        Loss function taking logits and target values.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    err : torch.Tensor\n",
        "        Scalar tensor with graph for updating generator.\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE\n",
        "    #raise NotImplementedError()\n",
        "\n",
        "    num_samples = real_x.size(0)\n",
        "\n",
        "    fake_z = gan.generator.sample(num_samples)\n",
        "    fake_x = gan.generator(fake_z)\n",
        "\n",
        "    fake_x.clamp_(min=-0.4242, max=2.8215) # MNIST range\n",
        "    discriminator_output = gan.discriminator(fake_x)\n",
        "\n",
        "    err = loss_func(discriminator_output, torch.ones_like(discriminator_output))\n",
        "\n",
        "\n",
        "    return err.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKPh-xvj74wT"
      },
      "outputs": [],
      "source": [
        "# Test Cell: do not edit or delete!\n",
        "gan = nn.ModuleDict({\n",
        "    'generator': Generator(),\n",
        "    'discriminator': Discriminator()\n",
        "})\n",
        "bce = nn.BCEWithLogitsLoss()\n",
        "\n",
        "try:\n",
        "    err = generator_error(gan, torch.randn(5, 1, 28, 28), bce)\n",
        "    grads = torch.autograd.grad(err, gan.generator.parameters())\n",
        "except RuntimeError:\n",
        "    raise AssertionError(\n",
        "        \"ex4: generator_error does not allow to compute gradients (-1 point)\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SR9Rcwj974wU"
      },
      "outputs": [],
      "source": [
        "# Test Cell: do not edit or delete!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VfbBOru874wU"
      },
      "outputs": [],
      "source": [
        "def discriminator_error(gan: nn.Module, real_x: torch.Tensor, loss_func: nn.Module):\n",
        "    \"\"\"\n",
        "    Construct the gradient graph for updating the discriminator.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    gan : nn.Module\n",
        "        Module with `generator` and `discriminator` sub-modules.\n",
        "    real_x: torch.Tensor\n",
        "        Mini-batch from target distribution.\n",
        "    loss_func: nn.Module\n",
        "        Loss function taking logits and target values.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    err : torch.Tensor\n",
        "        Scalar tensor with graph for updating discriminator.\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE\n",
        "    #raise NotImplementedError()\n",
        "\n",
        "\n",
        "    batch_size = real_x.shape[0]\n",
        "\n",
        "    fake_x = gan.generator.generate(batch_size = batch_size)\n",
        "\n",
        "    fake_logits = gan.discriminator(fake_x)\n",
        "    real_logits = gan.discriminator(real_x)\n",
        "\n",
        "    # Calculate the loss for the fake data and real data\n",
        "    real_loss = loss_func(real_logits, torch.ones_like(real_logits))\n",
        "    fake_loss = loss_func(fake_logits, torch.zeros_like(fake_logits))\n",
        "\n",
        "    err = real_loss + fake_loss\n",
        "\n",
        "    return err\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTfJ5zvp74wV"
      },
      "outputs": [],
      "source": [
        "# Test Cell: do not edit or delete!\n",
        "gan = nn.ModuleDict({\n",
        "    'generator': Generator(),\n",
        "    'discriminator': Discriminator()\n",
        "})\n",
        "bce = nn.BCEWithLogitsLoss()\n",
        "\n",
        "try:\n",
        "    err = discriminator_error(gan, torch.randn(5, 1, 28, 28), bce)\n",
        "    grads = torch.autograd.grad(err, gan.discriminator.parameters())\n",
        "except RuntimeError:\n",
        "    raise AssertionError(\n",
        "        \"ex4: discriminator_error does not allow to compute gradients (-1 point)\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oy_ktpi974wV"
      },
      "outputs": [],
      "source": [
        "# Test Cell: do not edit or delete!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzEW007774wV"
      },
      "outputs": [],
      "source": [
        "def update_gan(gan: nn.Module, loader: DataLoader, loss_func: nn.Module,\n",
        "               opt: optim.Optimizer):\n",
        "    \"\"\"\n",
        "    Train GAN for one epoch.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    gan : nn.Module\n",
        "        Module with `generator` and `discriminator` sub-modules.\n",
        "    loader : DataLoader\n",
        "        Standard, supervised data loader with samples from target distribution.\n",
        "    loss_func : nn.Module\n",
        "        Loss function taking logits and target values.\n",
        "    opt : optim.Optimizer\n",
        "        Optimiser for updating GAN parameters.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    g_errs : list\n",
        "        List of computed errors for generator update in each batch.\n",
        "    d_errs : list\n",
        "        List of computed errors for discriminator update in each batch.\n",
        "    \"\"\"\n",
        "    gan.train()\n",
        "    device = next(gan.parameters()).device\n",
        "\n",
        "    d_errs, g_errs = [], []\n",
        "    for x, _ in loader:\n",
        "        x = x.to(device)\n",
        "        # YOUR CODE HERE\n",
        "        # raise NotImplementedError()\n",
        "\n",
        "\n",
        "        opt.zero_grad()\n",
        "        # Compute the discriminator error using the provided GAN model.\n",
        "        d_err = discriminator_error(gan, x, loss_func)\n",
        "        # Perform backpropagation to compute the gradients for the discriminator.\n",
        "        d_err.backward()\n",
        "        d_errs.append(d_err.item())\n",
        "\n",
        "        # Compute the discriminator error using the provided GAN model.\n",
        "        g_err = generator_error(gan, x, loss_func)\n",
        "        g_err.backward()\n",
        "        # Append the computed generator error\n",
        "        g_errs.append(g_err.item())\n",
        "        # Update the weights of both the discriminator and the generator\n",
        "        opt.step()\n",
        "\n",
        "    #List of computed errors for discriminator update in each batch.\n",
        "    return  d_errs, g_errs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Tyhn5Rb74wW",
        "outputId": "86e3690d-7331-47b1-b00a-a31acaa2cdf0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "# Test Cell: do not edit or delete!\n",
        "gan = nn.ModuleDict({\n",
        "    'generator': Generator(),\n",
        "    'discriminator': Discriminator()\n",
        "}).to(device)\n",
        "bce = nn.BCEWithLogitsLoss()\n",
        "opt = optim.Adam(gan.parameters(), lr=1e-3)\n",
        "\n",
        "old_pars = {k: v.clone() for k, v in gan.state_dict().items()}\n",
        "g_errs, d_errs = update_gan(gan, [next(iter(train_loader))], bce, opt)\n",
        "assert len(g_errs) == len(test_loader), (\n",
        "    \"ex4: wrong number of generator errors in update_gan(-1 point)\"\n",
        ")\n",
        "assert len(d_errs) == len(test_loader), (\n",
        "    \"ex4: wrong number of discriminator errors in update_gan (-1 point)\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pEbHrYc674wW"
      },
      "outputs": [],
      "source": [
        "# Test Cell: do not edit or delete!\n",
        "assert all(\n",
        "    torch.any(old_pars[k] != par) for k, par in gan.state_dict().items()\n",
        "), \"ex4: update_gan does not update all parameters (-1 points)\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-zB5Nqz74wW"
      },
      "outputs": [],
      "source": [
        "# Test Cell: do not edit or delete!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        },
        "id": "WPbpTmJ374wX",
        "outputId": "422c4cb4-01ad-4124-d76d-ea4a9f02969d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  0 - avg G loss: 0.65492, avg D loss: 1.38903\n",
            "D probs: 0.52, 0.52, 0.52, 0.52, 0.52, 0.52, 0.52, 0.52, 0.52, 0.52\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=280x28>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "width": "100%"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  1 - avg G loss: 1.11210, avg D loss: 0.55877\n",
            "Epoch  2 - avg G loss: 1.33145, avg D loss: 0.47854\n",
            "Epoch  3 - avg G loss: 1.40880, avg D loss: 0.44692\n",
            "Epoch  4 - avg G loss: 1.34159, avg D loss: 0.46783\n",
            "Epoch  5 - avg G loss: 1.27130, avg D loss: 0.49517\n",
            "D probs: 0.46, 0.64, 0.60, 0.53, 0.60, 0.55, 0.43, 0.48, 0.52, 0.71\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=280x28>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "width": "100%"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  6 - avg G loss: 1.25974, avg D loss: 0.50211\n",
            "Epoch  7 - avg G loss: 1.28699, avg D loss: 0.49391\n",
            "Epoch  8 - avg G loss: 1.31314, avg D loss: 0.48678\n",
            "Epoch  9 - avg G loss: 1.31965, avg D loss: 0.48608\n",
            "Epoch  10 - avg G loss: 1.33057, avg D loss: 0.47807\n",
            "D probs: 0.77, 0.52, 0.62, 0.69, 0.65, 0.63, 0.51, 0.61, 0.58, 0.50\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=280x28>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAARgAAAAcCAAAAACfA//yAAAIBUlEQVR4nO2ZeXTNZxrHv6mKEhKxjE4dIoxIUfvWNvatpqh9SjkR02BGiXAsKS1DS9uxVIVETIjqONQy1lgiE1sssTSHItba0s7QxDCMNf3MH/cm997f772R06Mz03Pm+ee+z/N9n/Vdf++VfvbkX/y/HcH/6edNxX/9hA5Ni2LlmacQyU9E9bdHuhjfous1ySscJ+PHxeOiKgWtru+l/WlGYYVeQxHs/aooTrsuDFSFfj0SBu69R3JRFGw0aHdhaAhAkhkbXQTr5aUGNfIZ8ulyAe4504DZTzQZn/l8G2/YjILCltszNT2ZU6wDcooQqBRisUqhgzQWMPbo7l6xUD2bLw++WNDl5p6GuTlHfrnwnpOPlaQjqY06qio+TtkP7jYDJIXWOektlqm3B2w88c0UX783v7GD/okld155v6w+He3g7/xiik58GVG7xfG8t4cYzdWN9qvyirLKh+ZK8q0w9vQ6D/imO1OyumdU4+sPMMfoLFV4uI8klcxyg4bhRuPdlrduArGSVGvTxOsmq4MBPzXvafa5jVWHP0macHH3lVALEh4TFLInG66dOsjmCk7hZghztEqYrHWYkx/jwbw5Cq/dK9TSzWM+lC3mga3P1/W3WA0pyHyqpC6e4KBH9eu13n/kdgbdVbyUG3AWRjubPeMSDcHGclpqMnxWJQf7vCXSrPlhw77czP7EQFsKe+bfAvhnzNWDWwOdG+xvxjh+x1HW7mrTXy4DV2H3vRxub7ThvYBV+Yxv11qVLA4BGJi2+2VPtWygn/KAB5N6vdbYYtTb2rzjGoNt3LLji9JSpGptB58f5eAHeqDX2To1a+7hWDItp0UKcD4Z4M767ukjW1vqKSDA6mohGRyiUWldO/XDV6RbB17VgJoFXJnBfVt5GgTYmN11e3IHm69N0jyAOb0sNl9NIt7Rst4kXZNzODy2xqLpMEQBTRusxnBurYT4dzYAAQ0syAhgT9qBVO6yIaHNb6sHW/CNQBOruf18e+kx8xXOAWC4zR0wp4CZuIO5YS5sMlBfUttpNZdZt19Hin3MG3MaSV1sQkliP5JU7mhvIMEGb4Df1Ve7CXMibZB6/ADvtn8I3SxAcB9gValOJTuuX/B+Xam8Kcc7dazCHSyH84PnXTOnMBooJnWY2nRIoJT5LUPyV0U/XBqVAoF6Fme7JGkUQAV5Ur3YjKwBxv1zlsNoBpcA60ST4PsdlaTysSXtqpPg1Ivj/mZLIYbcSx9Imi6pYnODovyBgzZpq6PLyY7s3u3r7UtSDSsf2PmCEo9f33dhkF5MOTevshviquQ0oJJFcXIrSTppKveE5FzjzaHsF+7nlb10uWx6o6Mka6UlqRscPvPFCkMGOXysian3UkLbRWeMKm3XXAMca2UT1+kJmencokeMXScESBjS+O/fcYHhwTO2Ti9AwgCC+kuSXpm1C961hMPpXGcj2mq1fzIAqRF2f8lc++tHw6qEJQFnGlrhYRv7n12bMKl/D3ukGkge8aNs4soA544Ad7cthT8YNB8Bc8Pt8pkA3JgXp9o2bDBw8/QWtny1bf7Q197p40LOAH0lST6zl06rbNE7Co6D18c0YRQV9w/gqiFIF0Xm/DneJG8RFJAy0gRs5cYHtrNFkxyzLwcYAUyw6x0GsG0xkhIeO3TX9bF/KzZwnOQc5tKmoJjhrgHp5FpHa8g4YNUDYJmkGGNhpMZzB+zd+KkJKaDVYNsRSqhzm9l7sU8MKYhDKzbbfUVAAvCQ2xkzAcOXLGC8S2rl1n+R5aiNfYUugmxSl/RdunJY+0XRb7lbcwTR/777PcdJ5wHYsq1GiR3wtdGrdJJn2nqB8l00N4iXA9bzVpKiuJx87rhdHo2kyIywMZPHGAepGiBV/yTqIysSqJdOvLX2c0hkhF1vKrnERWlVkOSjNvnSygBRcs4cmNnZmtM6ZjXrMqA64O3NohO09gLlGzFIn3vVyxyERdevZtvlLd+TVMtfWp5kGHgpBRopqOUq6G0HK5aOfGP7dqPHmPNHbiS+PZEQJ+/XQpIiADi0MjXHUZj9m94McumUA1b2lKp8WMNLFpKk5EI/TlvC5zZhO0lwxtAdiDq5tRB7I403Iwl2ru656sNl+5j2rAF22jZIV55m130eFPD+krTM/Vjl5OoqHir1gc+qSoqLxvZWU228y99Zq7NK4yo3VoQkNTlnvQBI0suS4I/2KJsBixnfwEtqkuLAuJk/Brh6/yjsH+pF1VyYYgvW5Vpv4MEbPArzoJ1T7uf4GQ2Ol5+gM/bVcpT4oZJUkbt2d1UvApDHbIzRpEmJxiiTgEw8Pp1qurXL+x2ARQY9qXZBGpnTjR28FUbdjnnKfSWVWRtx3ZED/T9TZ4tGNAC77qY8zLZZbLV+H6x4LngEMN/ma6xHwQdZYf/xUZfhmCHIkVgr6TGJAx7A96bkJE1Idrq7+7EJrtsrHawZSpKanSDTaLFMYNrvjQ8Zr393wenrqB1sfeU+8Mg8IyTOALBn+5zL9jMrllxvm9YuoKMRkdQUYLI3VFJDKZIpjltxGQ+k9zKyOfeCUatDNeurwZMoeIyzMItNqN+UVGZsGFHYWR0lqa5dvDpv6OLxY4wazWcsMQ6SJCkd0q1PDTYabr8dStPWLzi54UiRHvuLRq9PZ3pCZKenZ1CS+RupKDTu6owfqflSPbX3/Q/+zWa6uf2EVDeslKfAx9zPTH6NnmYs/7NUTJICn9TLnUqXknmPeTpU7N/auPZGndtO9wAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "width": "100%"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  11 - avg G loss: 1.33359, avg D loss: 0.47818\n",
            "Epoch  12 - avg G loss: 1.32965, avg D loss: 0.48110\n",
            "Epoch  13 - avg G loss: 1.32953, avg D loss: 0.47811\n",
            "Epoch  14 - avg G loss: 1.32239, avg D loss: 0.48208\n",
            "Epoch  15 - avg G loss: 1.31747, avg D loss: 0.48441\n",
            "D probs: 0.73, 0.72, 0.52, 0.55, 0.68, 0.63, 0.89, 0.55, 0.64, 0.62\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=280x28>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAARgAAAAcCAAAAACfA//yAAAGNElEQVR4nO2YeXBX1RXHvy5FJFVplSIKNm0GOhRZVCAy0EoVs4CsFqyAQSQUhsVIiUDBhgQhVMpWIBDQNFQYmiYNAzSEQMqUpQiVIhgCsgjBGNSS0hKXuJDw6R+/YJL3zn0Zap1pR84/777v933POe/c5d37pKt21a7aV9VaTrhGanzDHRbXPjXyywk6o2zDi1+O5/+ebeM1gMqH/FQmAP9o84VjXOu5nzP7T/Pebe8Bh91z/4L5mxMXfOFoV2iZF3qY+Mf6RFLZjQP91Mh8Sbq1U6Df8Pq3zT5lBZDH337ilPR+u6Jt2F8H1AfzqTH/84vPLM/oqNbTvhaYyH9o+TDKwttfugCwEV72k4nPDpmy8enJ7zzjdNssuzqzHsDntvDJYZbi8G4GFvrhSZ/rRvi4LLJZdv4o+/mOMxFJGtx1WmI3A08CKnlc0opYL7cMuMXQ9E84zqt7JSXCbB/bInSh3E4kYenRLGBQXQz4gBOkFPVInml0vnYA3ws15772o1r8AHAyYc3JMj553qvpmLNneHyocs3tTKRvvhcq6wwf02nG70LU4rZxS/O8LLDC8nejuoQabaHKFdQY3hnUsVn1A31bUlNFri8cbvh6hR2SpBad5/H+5lq8J6F63Lzuct38FnPcKrWk1Ssr3gQust7PtYRNbCwtoGS29HUfbc5dzxMxLqrEr50I7AIOAvvqdgMvTAw14pKiov2uwrdUjpakZA6VUXdGte8Quj7BKXeOh62XuD4XOLt6XfZmDhs0nIy6+fuxCZS+FOZn18JiP7rwydp204DKWdSIn/WPhzdW7SgpLXmuDj4s5TexktSjU8QPLF+dN/SRFkN11vh6HXFXI6mV7t35OvHOPFQwywAXcZa+rXV3bHWOwVawsJUk9TtkrT76zHq3Yn5ce7PEXZjgweZZzkbEw9tjKSPLWLMkNSr98FWAp604ACQ7QyWSZKCfAnk9lGROiulV24ZId8YunbCgqaGdUG6I+vJ6vaxmOtI5xiMWnB8lqWMmOz14TO3as9TSvXkBPk6wGABKz9xrUPu5XcpeY072BwYsaTdOvzLrMp/pnSb9duVb808/akmVDLf60bT6SZlK6SmbuX6fpOZpBhkPnM+ptrck0kUucdSMNOqeb40bHbV196nlPgpWb8vds6WXqRs7eZ4iC6GZj7mPktRfn4BLefvMrUOj3Q0tvQeDJlJPFxUO3OTg4i45KlMFjAzKZYule1DtgjTScWP/o4GfUfTRaTacm0gLS3RtKZ0DvebBVgcVdipoUQ6q92BgkSnibFAyfwZ+alPNNdSZS6UBZgLzZs4cNfUiT1milBJyDbhd35ozzFagkZdtEj2n4Dkpq+7LN6n3xCQC6z0GGOdDI4GHxwfIpPBl5Qeu+PC6+T0DjE6ZEmq4ezDCwFY+1v2hrrnvcxjI97GjT/ySoQ+EuUdFNqwNSrWVJX0C2DOyb5BOUjXbTbyrU9GPLAseEppBidzl0C1s09qHZUDBzssfkHe97C0FRwqXRKibozDfjTnX4J4RDnmhHABdF6yTqLjdgjPfcglaBefinLtteqff5sVGAceoYvsr1wzKoHiMl3+GOd0lFVkhuwzfDmyfbkeLD43fm8A3IYC01IA3kCQ1fpa9Fj6YyS6Js5PWRkuCDQ5dh234zi2DQ0PlDwPCpJ/DBe8+9QArJSndGzICuOj6QSBJqRyUFLnrnxDnoTpCoiNFSXqxIPd4EbDLPO+q14e+3quxbOeAiVJqn9Pu4XQ/Bf6plJT2WHJNM6Z40+4UD90/J25VtFTo87oTyqvO7Q/4vvPBO0XmWTjNuYuUpEWX5/UbGSYfMciEJcF9DqZJt48qYa5L+HLFGXPS1ljL9f/64yZj87RuR7946OCFHz/G+R+6vXUvvvyC6V4qrCCr16O9zTOUJGnsXKD8iIN92HXsnuoeEnd25hAvOQO2+4V/wNS1R56fYv7FWvT7FUzww/3S/Fhd+3sx5/iL9WNs+Vk4Mv4Gt3TMHT3Nw56ku6f5uqjG4KDb45D0NQG92ICF92ls4l27D59iwN16B7trPItVQ+OnGsx1+kbwT7gA6+KK+sLehn6p/F9Yg9/qK7XbBqS7BtlX3Vzntf99+zcdsGmnZB0WfQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "width": "100%"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  16 - avg G loss: 1.31863, avg D loss: 0.48112\n",
            "Epoch  17 - avg G loss: 1.31567, avg D loss: 0.48569\n",
            "Epoch  18 - avg G loss: 1.30554, avg D loss: 0.48756\n",
            "Epoch  19 - avg G loss: 1.30321, avg D loss: 0.49251\n",
            "Epoch  20 - avg G loss: 1.30262, avg D loss: 0.48816\n",
            "D probs: 0.60, 0.61, 0.78, 0.48, 0.62, 0.57, 0.34, 0.47, 0.53, 0.56\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=280x28>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "width": "100%"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  21 - avg G loss: 1.29824, avg D loss: 0.49102\n",
            "Epoch  22 - avg G loss: 1.29750, avg D loss: 0.49178\n",
            "Epoch  23 - avg G loss: 1.29258, avg D loss: 0.49345\n",
            "Epoch  24 - avg G loss: 1.28396, avg D loss: 0.49689\n",
            "Epoch  25 - avg G loss: 1.28533, avg D loss: 0.49873\n",
            "D probs: 0.53, 0.72, 0.65, 0.70, 0.61, 0.42, 0.40, 0.65, 0.54, 0.51\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=280x28>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "width": "100%"
          }
        }
      ],
      "source": [
        "# sanity check\n",
        "gan = nn.ModuleDict({\n",
        "    'generator': Generator(),\n",
        "    'discriminator': Discriminator()\n",
        "}).to(device)\n",
        "bce = nn.BCEWithLogitsLoss()\n",
        "opt = optim.Adam([\n",
        "    {'params': gan.generator.parameters(), 'lr': 1e-3},\n",
        "    {'params': gan.discriminator.parameters(), 'lr': 2e-4}\n",
        "])\n",
        "train_gan(gan, train_loader, bce, opt, num_epochs=25)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}